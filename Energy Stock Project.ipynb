{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "    import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epd_df = pd.read_csv(\"EPD.csv\", encoding='utf-8')\n",
    "epd_df.rename(columns={\"Open\":\"Open_EPD\", \"Close\": \"Close_EPD\"}, inplace = True)\n",
    "epd_df[\"Monthly_Change_EPD\"] = epd_df[\"Open_EPD\"] - epd_df[\"Close_EPD\"]\n",
    "\n",
    "kmi_df = pd.read_csv(\"KMI.csv\", encoding='utf-8')\n",
    "kmi_df.rename(columns={\"Open\":\"Open_KMI\", \"Close\": \"Close_KMI\"}, inplace = True)\n",
    "kmi_df[\"Monthly_Change_KMI\"] = kmi_df[\"Open_KMI\"] - kmi_df[\"Close_KMI\"]\n",
    "kmi_df = kmi_df.drop(columns=[\"Date\"])\n",
    "\n",
    "mmp_df = pd.read_csv(\"MMP.csv\", encoding='utf-8')\n",
    "mmp_df.rename(columns={\"Open\":\"Open_MMP\", \"Close\": \"Close_MMP\"}, inplace = True)\n",
    "mmp_df[\"Monthly_Change_MMP\"] = mmp_df[\"Open_MMP\"] - mmp_df[\"Close_MMP\"]\n",
    "mmp_df = mmp_df.drop(columns=[\"Date\"])\n",
    "\n",
    "mplx_df = pd.read_csv(\"MPLX.csv\", encoding='utf-8')\n",
    "mplx_df.rename(columns={\"Open\":\"Open_MPLX\", \"Close\": \"Close_MPLX\"}, inplace = True)\n",
    "mplx_df[\"Monthly_Change_MPLX\"] = mplx_df[\"Open_MPLX\"] - mplx_df[\"Close_MPLX\"]\n",
    "mplx_df = mplx_df.drop(columns=[\"Date\"])\n",
    "\n",
    "et_df = pd.read_csv(\"ET.csv\", encoding='utf-8')\n",
    "et_df.rename(columns={\"Open\":\"Open_ET\", \"Close\": \"Close_ET\"}, inplace = True)\n",
    "et_df[\"Monthly_Change_ET\"] = et_df[\"Open_ET\"] - et_df[\"Close_ET\"]\n",
    "et_df = et_df.drop(columns=[\"Date\"])\n",
    "\n",
    "xom_df = pd.read_csv(\"XOM.csv\", encoding='utf-8')\n",
    "xom_df.rename(columns={\"Open\":\"Open_XOM\", \"Close\": \"Close_XOM\"}, inplace = True)\n",
    "xom_df[\"Monthly_Change_XOM\"] = xom_df[\"Open_XOM\"] - xom_df[\"Close_XOM\"]\n",
    "xom_df = xom_df.drop(columns=[\"Date\"])\n",
    "\n",
    "unemployment_df = pd.read_csv(\"USUnemployment.csv\", encoding = 'utf-8')\n",
    "\n",
    "cci_df = pd.read_csv(\"CCI.csv\", encoding='utf-8')\n",
    "\n",
    "nasdaq_df = pd.read_csv(\"IXIC.csv\", encoding='utf-8')\n",
    "nasdaq_df.rename(columns={\"Open\":\"Open_NASDAQ\", \"Close\": \"Close_NASDAQ\"}, inplace = True)\n",
    "nasdaq_df[\"Monthly_Change_NASDAQ\"] = nasdaq_df[\"Open_NASDAQ\"] - nasdaq_df[\"Close_NASDAQ\"]\n",
    "nasdaq_df = nasdaq_df.drop(columns=[\"Date\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([epd_df, kmi_df, mmp_df, mplx_df, nasdaq_df, et_df, xom_df], axis=1, join=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result.dropna()\n",
    "result = result.drop(columns=[\"High\", \"Low\", \"Adj Close\", \"Volume\"])\n",
    "result = result.iloc[1:]\n",
    "final_result = result.iloc[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment_monthly = pd.DataFrame\n",
    "unemployment_monthly_dates = []\n",
    "unemployment_monthly_rates = []\n",
    "for x in range(64,72):\n",
    "    unemployment_monthly_rates.append(unemployment_df[\"Jan\"][x])\n",
    "    unemployment_monthly_rates.append(unemployment_df[\"Feb\"][x])\n",
    "    unemployment_monthly_rates.append(unemployment_df[\"Mar\"][x])\n",
    "    unemployment_monthly_rates.append(unemployment_df[\"Apr\"][x])\n",
    "    unemployment_monthly_rates.append(unemployment_df[\"May\"][x])\n",
    "    unemployment_monthly_rates.append(unemployment_df[\"Jun\"][x])\n",
    "    unemployment_monthly_rates.append(unemployment_df[\"Jul\"][x])\n",
    "    unemployment_monthly_rates.append(unemployment_df[\"Aug\"][x])\n",
    "    unemployment_monthly_rates.append(unemployment_df[\"Sep\"][x])\n",
    "    unemployment_monthly_rates.append(unemployment_df[\"Oct\"][x])\n",
    "    unemployment_monthly_rates.append(unemployment_df[\"Nov\"][x])\n",
    "    unemployment_monthly_rates.append(unemployment_df[\"Dec\"][x])\n",
    "\n",
    "unemployment_monthly_rates.append(3.6)\n",
    "unemployment_monthly_rates.append(3.5)\n",
    "unemployment_monthly_rates.append(4.4)\n",
    "unemployment_monthly_rates.append(14.7)\n",
    "unemployment_monthly_rates.append(13.3)\n",
    "unemployment_monthly_rates.append(11.1)\n",
    "unemployment_monthly_rates.append(10.2)\n",
    "unemployment_monthly_rates.append(8.4)\n",
    "unemployment_monthly_rates.append(7.8)\n",
    "unemployment_monthly_rates.append(6.9)\n",
    "unemployment_monthly_rates.append(6.7)\n",
    "unemployment_monthly_rates.append(6.7)\n",
    "\n",
    "del unemployment_monthly_rates[0:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result[\"Unemployment_Rate\"] = unemployment_monthly_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cci_df_new = cci_df[cci_df[\"LOCATION\"] == \"USA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cci_df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cci_df_new_values = cci_df_new[\"Value\"]\n",
    "final_result[\"CCI_Values\"] = cci_df_new_values.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, random_state=1)\n",
    "\n",
    "def RFE_feature_selection():\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X_train)\n",
    "    \n",
    "    select = RFE(DecisionTreeRegressor(random_state=1), n_features_to_select=3)\n",
    "    \n",
    "    #fit the RFE selector to the training data\n",
    "    select.fit(X_train, y_train)\n",
    "\n",
    "    #transform training and testing sets so only the selected features are retained\n",
    "    X_train_selected = select.transform(X_train)\n",
    "    X_test_selected = select.transform(X_test)\n",
    "    \n",
    "    model = Ridge().fit(X=X_train_selected, y=y_train)\n",
    "    \n",
    "    print(\"Selected features after RFE:\")\n",
    "    for i in range(len(select.get_support())):\n",
    "        if select.get_support()[i]:\n",
    "            print(features.columns[i]) #gets the features for which get_support is true\n",
    "    \n",
    "    accuracy_train = model.score(X_train_selected, y_train)\n",
    "    accuracy_test = model.score(X_test_selected, y_test)\n",
    "\n",
    "    print(\"\\nkNN Classification performance with selected features:\")\n",
    "    print(\"\\t Prediction accuracy on the train data:\", f\"{accuracy_train:.2%} \\n\")\n",
    "    print(\"\\t Prediction accuracy on the test data:\", f\"{accuracy_test:.2%} \\n\")\n",
    "\n",
    "RFE_feature_selection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = final_result[[\"Monthly_Change_KMI\",\"Monthly_Change_MPLX\", \"CCI_Values\"]]\n",
    "target = final_result[\"Monthly_Change_ET\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import LinearSVR\n",
    "\n",
    "estimators = {\n",
    "    'Linear Regression': LinearRegression(), \n",
    "    'Ridge': Ridge(alpha = 0.001),\n",
    "    'Lasso': Lasso(alpha = 0.001),\n",
    "    'K-Nearest Neighbors Regressor': KNeighborsRegressor(n_neighbors = 3),\n",
    "    'Linear SVC': LinearSVR(C=0.01, max_iter = 100)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "def regressors_percentage_split():\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target, random_state=37)\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    for estimator_name, estimator_object in estimators.items():\n",
    "        estimator_object.fit(X=X_train_scaled, y=y_train)\n",
    "        accuracy = estimator_object.score(X_test_scaled, y_test)\n",
    "        print(estimator_name)\n",
    "        print(\"\\t Prediction accuracy on the test data:\", f\"{accuracy:.2%} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressors_percentage_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\"alpha\":[0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#import GridSearchCV and fit GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_search = GridSearchCV(Ridge(), param_grid, cv=5)\n",
    "\n",
    "#split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, random_state=3000)\n",
    "\n",
    "#fit the grid search object on the training data (CV will be performed on this)\n",
    "grid_search.fit(X=X_train, y=y_train)\n",
    "\n",
    "#result of grid search\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "print(\"Best cross-validation score: \", grid_search.best_score_)\n",
    "\n",
    "#the performance of the best found parameters on the test set\n",
    "#this is what you report for the evaluation of your model\n",
    "print(\"Test set score: \", grid_search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Lasso(alpha=0.001).fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict([[0.005, -5.123, 98.67]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('model_pickle', 'wb') as f:\n",
    "    pickle_dump(model, f)\n",
    "with open('model_pickle', 'rb') as f:\n",
    "    mp = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "et2_df = pd.read_csv(\"ET2.csv\", encoding='utf-8', date_parser = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "et_train = et2_df[et2_df['Date'] < '2019-01-01'].copy()\n",
    "\n",
    "et_test = et2_df[et2_df['Date'] >= '2019-01-01'].copy()\n",
    "\n",
    "training_data = et_train.drop(['Date', 'Adj Close'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "training_data = scaler.fit_transform(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "for i in range(60, training_data.shape[0]):\n",
    "    X_train.append(training_data[i-60:i])\n",
    "    y_train.append([i,0])\n",
    "\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "past_60_days = et_train.tail(60)\n",
    "df_past_60 = past_60_days.append(et_test, ignore_index = True)\n",
    "df_past_60 = df_past_60.drop([\"Date\", \"Adj Close\"], axis=1)\n",
    "\n",
    "inputs = scaler.fit_transform(df_past_60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "for i in range(60, inputs.shape[0]):\n",
    "    X_test.append(inputs[i-60:i])\n",
    "    y_test.append(inputs[i, 0])\n",
    "    \n",
    "X_test, y_test = np.array(X_test), np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = Sequential()\n",
    "\n",
    "regressor.add(LSTM(units = 60, activation = 'relu', return_sequences = True, input_shape = (X_train.shape[1], 5)))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "regressor.add(LSTM(units = 60, activation = 'relu', return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "regressor.add(LSTM(units = 80, activation = 'relu', return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "regressor.add(LSTM(units = 120, activation = 'relu'))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "regressor.add(Dense(units = 1, activation = 'linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = SGD(lr = 0.01, momentum = 0.9, clipnorm = 1.0)\n",
    "regressor.compile(optimizer=opt, loss='mean_squared_logarithmic_error', metrics=[\"mse\"])\n",
    "regressor.fit(X_train, y_train, epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
